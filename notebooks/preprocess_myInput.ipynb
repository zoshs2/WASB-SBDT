{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Custom video preprocessing for WASB tennis inference\n",
        "\n",
        "This notebook converts sample videos placed under `myInput/game*/sample*.mp4` into the frame/CSV layout expected by the tennis dataloader, so you can run inference with visualization overlays on CPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Prerequisites\n",
        "- Place your MP4 files under `myInput/game*/sample*.mp4` (e.g., `myInput/game1/sample1.mp4`).\n",
        "- The notebook writes frames and placeholder annotations to `myInput_prepared/<game>/<sample>/`.\n",
        "- The generated `Label.csv` marks every frame as `visibility=0` with empty coordinates so inference runs without requiring ground-truth labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "'/Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/notebooks'"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "BasePath = '/Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4 videos\n",
            " - /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game1/sample1.mp4\n",
            " - /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game2/sample2.mp4\n",
            " - /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game3/sample3.mp4\n",
            " - /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game4/sample4.mp4\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "\n",
        "# Input and output roots\n",
        "input_root = BasePath / Path('myInput')\n",
        "output_root = BasePath / Path('myInput_prepared')\n",
        "output_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Video glob pattern (game*/sample*.mp4)\n",
        "video_paths = sorted(input_root.glob('game*/sample*.mp4'))\n",
        "print(f'Found {len(video_paths)} videos')\n",
        "for p in video_paths:\n",
        "    print(' -', p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_video_to_clip(video_path: Path, clip_root: Path, ext: str = '.jpg', fps_limit: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Extract frames from a video into `clip_root`, and emit a placeholder Label.csv.\n",
        "\n",
        "    Args:\n",
        "        video_path: path to the input MP4 file.\n",
        "        clip_root: directory where frames and Label.csv will be stored.\n",
        "        ext: image extension to use for saved frames.\n",
        "        fps_limit: optional integer to cap the number of frames per second (skip frames evenly).\n",
        "    \"\"\"\n",
        "    clip_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f'Cannot open video: {video_path}')\n",
        "\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS) or 0\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f'Processing {video_path} ({frame_count} frames @ {original_fps:.1f} fps)')\n",
        "\n",
        "    # Decide sampling stride if we need to limit FPS\n",
        "    stride = 1\n",
        "    if fps_limit and original_fps > fps_limit:\n",
        "        stride = max(1, int(round(original_fps / fps_limit)))\n",
        "        print(f' - downsampling frames with stride={stride}')\n",
        "\n",
        "    saved_files = []\n",
        "    idx = 0\n",
        "    saved_idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        idx += 1\n",
        "        if idx % stride:\n",
        "            continue\n",
        "\n",
        "        fname = f\"{saved_idx:06d}{ext}\"\n",
        "        fpath = clip_root / fname\n",
        "        cv2.imwrite(str(fpath), frame)\n",
        "        saved_files.append(fname)\n",
        "        saved_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f' - saved {len(saved_files)} frames to {clip_root}')\n",
        "\n",
        "    # Create placeholder Label.csv expected by tennis loader\n",
        "    df = pd.DataFrame({\n",
        "        'file name': saved_files,\n",
        "        'visibility': [0] * len(saved_files),  # 0 => not visible (no GT)\n",
        "        'x-coordinate': [np.nan] * len(saved_files),\n",
        "        'y-coordinate': [np.nan] * len(saved_files),\n",
        "    })\n",
        "    csv_path = clip_root / 'Label.csv'\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f' - wrote {csv_path}')\n",
        "\n",
        "    return saved_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game1/sample1.mp4 (13562 frames @ 30.0 fps)\n",
            " - saved 13559 frames to /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample1\n",
            " - wrote /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample1/Label.csv\n",
            "Processing /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game2/sample2.mp4 (1950 frames @ 30.0 fps)\n",
            " - saved 1950 frames to /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample2\n",
            " - wrote /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample2/Label.csv\n",
            "Processing /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game3/sample3.mp4 (28982 frames @ 30.0 fps)\n",
            " - saved 28979 frames to /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample3\n",
            " - wrote /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample3/Label.csv\n",
            "Processing /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput/game4/sample4.mp4 (4619 frames @ 30.0 fps)\n",
            " - saved 4619 frames to /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample4\n",
            " - wrote /Users/yungi/Documents/MyQBicware/BM/myTracker/WASB-SBDT/myInput_prepared/myInput/sample4/Label.csv\n"
          ]
        }
      ],
      "source": [
        "# Run extraction for every detected video\n",
        "for video_path in video_paths:\n",
        "    game_dir = video_path.parent.parent.name  # e.g., game1\n",
        "    clip_dir = video_path.stem                # e.g., sample1\n",
        "    clip_root = output_root / game_dir / clip_dir\n",
        "    extract_video_to_clip(video_path, clip_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## How to run inference with overlays (CPU)\n",
        "After preparing the clips, run the WASB tennis model on CPU and save overlay frames:\n",
        "```bash\n",
        "python3 main.py --config-name=eval_cpu   dataset=tennis model=wasb   dataset.root_dir=/workspace/myInput_prepared/myInput   dataset.test.matches=[sample1,sample2,sample3,sample4]   runner.device=cpu runner.gpus=[]   runner.vis_result=true   detector.model_path=../pretrained_weights/wasb_tennis_best.pth.tar   dataloader.num_workers=2\n",
        "```\n",
        "- Overlays are saved under `outputs/eval_cpu/<timestamp>/` per clip.\n",
        "- Add `runner.vis_hm=true` or `runner.vis_traj=true` if you also want heatmaps or trajectory plots.\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.20 64-bit ('wasb_sbdt': conda)",
      "name": "python3820jvsc74a57bd0d2ea79ce4e990433211d238dc91cbcd2e6d700699b7379db5ba1d5fc57f38804"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "d2ea79ce4e990433211d238dc91cbcd2e6d700699b7379db5ba1d5fc57f38804"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}